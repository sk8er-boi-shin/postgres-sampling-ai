# 目次
 
1. [はじめに](#1はじめに)  
2. [背景と目的](#2背景と目的)  
3. [対象範囲](#3対象範囲)  
4. [全体構成](#4全体構成) 
5. [処理概要](#5処理概要)  
6. [処理フローとロジック概要](#6処理フローとロジック概要)  

📘 **本ドキュメントで使用する用語や技術的な前提知識については、[参考資料・用語集](./03_reference.md#前提知識) を参照してください。**

---
# 1.はじめに

本ドキュメントは、PostgreSQLにおける統計情報の更新処理に対して、AIを用いて最適なサンプリング行数を自動算出し、処理効率を向上させるツールの基本設計をまとめたものである。

PostgreSQLではクエリ最適化のために統計情報が使用されるが、その更新には `ANALYZE` の実行が必要であり、対象テーブルの規模や特性によって処理時間や精度に大きく差が出る。本プロジェクトでは、以下のような課題に対処するための仕組みを設計する。

- 大規模テーブルに対する ANALYZE の長時間実行
- 統計情報の不整合による実行計画の非最適化
- 更新頻度やデータ特性に応じた最適なサンプリング戦略の不足
- パーティションテーブルや断片化されたテーブルへの対応
- `pg_stat` 系情報の遅延反映や推定値によるブレの吸収


本設計書では、これらの問題を解決するためのシステム構成、処理フロー、入出力仕様、そしてサンプリング行数をAIにより動的に算出するロジックの設計について詳細に述べる。

また、本ツールはPoC（Proof of Concept）としてローカル実行可能なスクリプトから開始し、将来的にはクラウド環境でのスケーラブルな実行や、Web UIとの連携を視野に入れている。


---

# 2.背景と目的

PostgreSQLでは、クエリの最適な実行計画を生成するために、テーブルごとの統計情報が利用される。  

しかし、これらの統計情報は `ANALYZE` により手動または自動で収集される必要があり、
その際にはテーブル全体からランダムにサンプリングされた行に対して統計を収集する。

サンプリングされる行数は PostgreSQL が内部的に計算しており、
通常は各列に対して `default_statistics_target` の値（デフォルトでは100）を基準に必要な数だけ選ばれる。

この値は列ごとに変更可能であり、精度と処理負荷のバランスを調整できるが、
テーブルの規模や構造によっては、サンプリングであっても一定の処理負荷や実行時間がかかるという課題がある。


また、PostgreSQLの自動ANALYZEは、トリガー条件（更新率やタイミング）に依存しており、実際の運用環境では以下のような問題が発生しやすい：

- 更新頻度やデータ特性に応じた最適なサンプリング戦略が存在しない
- フルスキャンとサンプリングの使い分けに明確な指針がない
- ユーザーや運用担当者による属人的なANALYZE実行の判断

さらに、パーティションテーブルや断片化が進行したテーブルにおいては、統計情報の不整合が発生しやすく、実行計画の選定ミスを招く要因となる。

そこで本プロジェクトでは、AIを用いてテーブルごとの特性（件数、更新率、カーディナリティ、ユニーク度など）を動的に分析し、最適なサンプリング行数を自動で算出する仕組みを開発する。

本ツールにより、以下のような価値を提供することを目的とする：

- 統計情報の収集時間を短縮し、ANALYZEの運用効率を向上
- 実データに即したサンプリング行数を推定し、実行計画の精度向上を図る
- 手動調整や試行錯誤を減らし、統計情報の運用自動化を実現

この設計書では、上記の課題を解決するための構成方針、実行ロジック、AIによる推定アプローチ、考慮すべき仕様について述べる。


---

# 3.対象範囲

本設計における対象範囲は以下のとおりである。

### 対象とする処理範囲

- PostgreSQL データベースに対する統計情報の更新 (`ANALYZE`) 処理
- `default_statistics_target` を基準としたサンプリング行数の最適化
- 対象テーブルごとに動的なサンプリング行数を算出し、`ANALYZE` を実行するスクリプトの設計
- 通常のローカルテーブルおよびパーティションテーブルの統計情報更新

### 対象外とする項目

- 外部テーブル（Foreign Tables）やFDWを介したテーブルへの対応
- PostgreSQL 以外の RDBMS（MySQL, Oracle, SQL Server など）への対応  
  ※現時点では PostgreSQL のみを対象とするが、本プロジェクトの成果が安定・有効と判断されれば、他の主要RDBMSへの拡張も将来的な検討対象とする。
- 自動統計情報更新の PostgreSQL 本体の挙動変更や、サーバパラメータの制御
- Web UI やダッシュボードによる可視化機能（将来的な拡張対象）

### 想定環境

- PostgreSQL 13 以上を対象とし、特に `parallel analyze` の恩恵を受けられるバージョンを想定
- 開発・実行環境はローカルPCまたは軽量VPS
- 本番環境への導入は将来的なPoC結果に基づき判断


---
# 4.全体構成

本ツールは、PostgreSQLの統計情報更新に関わるパフォーマンスを改善することを目的とし、  
AIによる最適なサンプリング行数の推定と、それに基づく `ANALYZE` 処理を実行するアプリケーションである。

初期フェーズではローカル実行環境を想定し、将来的にはクラウド環境やWeb UIとの統合も視野に入れている。

本ツールは、以下の2つのフェーズで構成される：

- **学習フェーズ**：クエリ実行前後の統計情報・実行計画を収集し、最適なサンプリング行数をAIで学習
- **適用フェーズ**：学習済みモデルを使用して、推定されたサンプリング行数で本番環境にANALYZEを適用


## 学習フェーズと適用フェーズの処理概要

```
[学習フェーズ：開発環境やPoCで実行]
↓
1. クエリを指定
↓
2. 含まれるテーブルごとに以下を繰り返し実行：
   - 統計情報メトリクスの取得（pg_stat等）
   - AIによるサンプリング行数の推定
   - 推定結果に基づく ANALYZE の実行
   - 実行計画の取得と処理時間の記録
↓
3. 実行計画や統計情報をもとに AI を再学習
↓
4. 学習済みモデルをファイルに保存（例：best_model.pkl）

↓

[適用フェーズ：本番環境などで実行]
↓
1. クエリを指定
↓
2. 含まれるテーブルのメトリクスのみを取得
↓
3. 学習済みモデルでサンプリング行数を推定
↓
4. 推定値に基づいて ANALYZE を実行
   （または dry-run モードでログ出力）
```




## コンポーネント構成

以下に、学習フェーズおよび適用フェーズを支えるモジュール構成を示す：

### 学習フェーズにおける構成

#### 1. サンプリング最適化エンジン（AIロジック部）
- 過去の実行ログや統計情報をもとに、各テーブルに対する適切なサンプリング行数を推定
- 現在は単純なルールベースまたは回帰モデルを採用し、将来的に強化学習やクラスタリングへの展開も視野に入れる
- 学習済みモデルはファイル（例：Pickle形式）として保存され、適用フェーズで再利用される

#### 2. メトリクス取得モジュール
- `pg_stat_all_tables`、`pg_stat_user_indexes`、`pg_class` などのシステムカタログから統計・構造情報を収集
- `reltuples`、`n_dead_tup`、カーディナリティ、相関係数などを収集対象とする
- クエリに含まれるすべてのテーブルが対象となる

#### 3. 統計更新・実行計画収集モジュール
- 推定されたサンプリング行数をもとに `ANALYZE` を実行し、統計情報を更新
- 続いて対象クエリを実行し、得られた実行計画と実行時間を記録
- 結果は履歴管理テーブルまたはログファイルに保存され、学習に再利用される


### 適用フェーズにおける構成

#### 4. 学習済みモデル適用モジュール
- 学習済みモデルファイルを読み込み、対象テーブルに対してサンプリング行数を推定
- モデルと特徴量に不整合がある場合は既定値にフォールバックする設計とする（フェールセーフ）

#### 5. サンプリング実行・統計更新モジュール（本番適用）
- 推定されたサンプリング行数に従って、`ANALYZE` を実行
- 対象はクエリに含まれるテーブルに限定される
- 統計情報の更新後、実行計画を取得することなく、本番処理を継続可能

### 共通機能

#### 6. ログ・エラーハンドリング機構
- 実行結果や異常検知のログ出力
- エラー発生時のリトライ処理、対象除外、学習フェーズへのフィードバック処理を含む

#### 7. （将来的な構想）Web UI / API連携モジュール
- クエリパターンや予測モデルの可視化
- サンプリング精度や効果の分析画面
- バックエンドAPI連携によるCI/CD統合の検討



---


# 5.処理概要

本ツールは、PostgreSQLにおける統計情報更新処理のパフォーマンス最適化を目的とし、  
AIを用いてテーブルごとに適切なサンプリング行数を推定し、`ANALYZE` 処理に適用することで、更新時間の短縮と最適化を図る。

本ツールは、以下2つのフェーズに分かれて動作する：

- **学習フェーズ（PoC／開発環境想定）**  
　統計情報と実行計画を収集し、最適なサンプリング行数をAIで学習する

- **適用フェーズ（本番想定）**  
　学習済みモデルを用いてサンプリング行数を推定し、`ANALYZE` に適用する


```

[学習フェーズ]
↓
1. クエリを指定
↓
2. クエリに含まれる各テーブルに対して以下を実行：
   - 統計情報の取得
   - AIによるサンプリング行数の推定
   - ANALYZE の実行と統計更新
   - 実行計画と実行時間の取得・記録
↓
3. 実行結果をもとにモデルを再学習し、ファイル保存

↓

[適用フェーズ]
↓
1. クエリを指定
↓
2. テーブルごとにメトリクスを取得
↓
3. 学習済みモデルによりサンプリング行数を推定
↓
4. 推定結果に基づき ANALYZE を実行

```

※詳細なモジュール構成については、[全体構成](#4全体構成)を参照。

---


# 6.処理フローとロジック概要

本章では、前章「全体構成」で定義した **学習フェーズ** および **適用フェーズ** に基づき、  
各フェーズにおける処理の流れと、主なロジックの概要を示す。


### 学習フェーズ：処理フローとロジック概要

学習フェーズは、開発環境やPoC環境を前提とし、  
AIが最適なサンプリング行数を学習するための一連の処理を実行する。

#### 処理フロー

1. クエリの指定
2. クエリに含まれるテーブルを抽出
3. 各テーブルについて以下を繰り返し実行：
   - システムカタログから統計情報・構造情報を取得（`pg_stat_all_tables`, `pg_class` 等）
   - AI によるサンプリング行数の推定
   - 推定行数を使用して `ANALYZE` を実行
   - 対象クエリの実行計画と処理時間を記録
4. 実行結果をもとにAIを再学習
5. 学習済みモデル（例：`best_model.pkl`）として保存

#### ロジック概要

- 特徴量には reltuples、n_dead_tup、カーディナリティ、相関係数などを使用
- AIロジックには単純な回帰モデルまたはルールベースを適用（将来的に強化学習等に拡張予定）
- 異常値の除外や最低／最大サンプル数の制約を設けて安全性を担保
- モデル保存時には特徴量スキーマも併せて記録（不整合防止のため）



### 適用フェーズ：処理フローとロジック概要

適用フェーズでは、本番環境において学習済みモデルを活用し、  
指定されたクエリの対象テーブルに対して適切な `ANALYZE` を実行する。

#### 処理フロー

1. クエリの指定
2. クエリに含まれるテーブルを抽出
3. 各テーブルについて以下を実行：
   - メトリクス（統計・構造情報）の取得
   - 学習済みモデルに基づくサンプリング行数の推定
   - 推定行数を使用して `ANALYZE` を実行  
     ※ dry-run オプション時はログ出力のみ

#### ロジック概要

- モデル読み込み時に、特徴量スキーマとの不整合があれば安全な既定値にフォールバック
- 複数テーブルに対応した並列実行をサポート（最大同時実行数は設定可能）
- 推定結果はログに記録し、dry-run 時は JSON または CSV 形式で出力
- 本番環境では実行計画の取得は行わず、ANALYZE のみ実行することで影響を最小化



### 共通機能・補足事項

- **ログ・エラー処理**：各ステップの処理結果、エラー、異常判定ログを記録し、学習フェーズへのフィードバックにも活用
- **閾値管理**：最小／最大サンプリング行数のしきい値を設定し、極端な推定値を自動調整
- **拡張性**：
  - Web UI からの操作や結果可視化を将来的に検討
  - モデルのCI/CD連携や自動評価機能の導入も視野に入れる


---