# 目次

1. [はじめに](#はじめに)  
2. [背景と目的](#背景と目的)  
3. [対象範囲](#対象範囲)  
4. [全体構成](#全体構成)  
5. [機能要件](#機能要件)  
6. [非機能要件](#非機能要件)  
7. [技術選定（使用技術と実行環境）](#技術選定使用技術と実行環境)  
8. [処理概要](#処理概要)  
9. [入出力仕様](#入出力仕様)  
10. [モジュール構成](#モジュール構成)  
11. [考慮すべきデータ構造と仕様](#考慮すべきデータ構造と仕様)  
12. [処理フローとロジック概要](#処理フローとロジック概要)  
13. [外部インターフェース（DB/API等）](#外部インターフェースdbapi等)  
14. [AIによるサンプリング行数の推定ロジック](#aiによるサンプリング行数の推定ロジック)  
15. [エラーハンドリング・ロギング](#エラーハンドリングロギング)  
16. [今後の拡張案](#今後の拡張案)  
17. [参考資料・用語集](#参考資料用語集)




---
# はじめに

本ドキュメントは、PostgreSQLにおける統計情報の更新処理に対して、AIを用いて最適なサンプリング行数を自動算出し、処理効率を向上させるツールの基本設計をまとめたものである。

PostgreSQLではクエリ最適化のために統計情報が使用されるが、その更新には `ANALYZE` の実行が必要であり、対象テーブルの規模や特性によって処理時間や精度に大きく差が出る。本プロジェクトでは、以下のような課題に対処するための仕組みを設計する。

- 大規模テーブルに対する ANALYZE の長時間実行
- 統計情報の不整合による実行計画の非最適化
- 更新頻度やデータ特性に応じた最適なサンプリング戦略の不足
- パーティションテーブルや断片化されたテーブルへの対応
- `pg_stat` 系情報の遅延反映や推定値によるブレの吸収


本設計書では、これらの問題を解決するためのシステム構成、処理フロー、入出力仕様、そしてサンプリング行数をAIにより動的に算出するロジックの設計について詳細に述べる。

また、本ツールはPoC（Proof of Concept）としてローカル実行可能なスクリプトから開始し、将来的にはクラウド環境でのスケーラブルな実行や、Web UIとの連携を視野に入れている。


---

# 背景と目的

PostgreSQLでは、クエリの最適な実行計画を生成するために、テーブルごとの統計情報が利用される。  

しかし、これらの統計情報は `ANALYZE` により手動または自動で収集される必要があり、
その際にはテーブル全体からランダムにサンプリングされた行に対して統計を収集する。

サンプリングされる行数は PostgreSQL が内部的に計算しており、
通常は各列に対して `default_statistics_target` の値（デフォルトでは100）を基準に必要な数だけ選ばれる。

この値は列ごとに変更可能であり、精度と処理負荷のバランスを調整できるが、
テーブルの規模や構造によっては、サンプリングであっても一定の処理負荷や実行時間がかかるという課題がある。


また、PostgreSQLの自動ANALYZEは、トリガー条件（更新率やタイミング）に依存しており、実際の運用環境では以下のような問題が発生しやすい：

- 更新頻度やデータ特性に応じた最適なサンプリング戦略が存在しない
- フルスキャンとサンプリングの使い分けに明確な指針がない
- ユーザーや運用担当者による属人的なANALYZE実行の判断

さらに、パーティションテーブルや断片化が進行したテーブルにおいては、統計情報の不整合が発生しやすく、実行計画の選定ミスを招く要因となる。

そこで本プロジェクトでは、AIを用いてテーブルごとの特性（件数、更新率、カーディナリティ、ユニーク度など）を動的に分析し、最適なサンプリング行数を自動で算出する仕組みを開発する。

本ツールにより、以下のような価値を提供することを目的とする：

- 統計情報の収集時間を短縮し、ANALYZEの運用効率を向上
- 実データに即したサンプリング行数を推定し、実行計画の精度向上を図る
- 手動調整や試行錯誤を減らし、統計情報の運用自動化を実現

この設計書では、上記の課題を解決するための構成方針、実行ロジック、AIによる推定アプローチ、考慮すべき仕様について述べる。


---

# 対象範囲

本設計における対象範囲は以下のとおりである。

### 対象とする処理範囲

- PostgreSQL データベースに対する統計情報の更新 (`ANALYZE`) 処理
- `default_statistics_target` を基準としたサンプリング行数の最適化
- 対象テーブルごとに動的なサンプリング行数を算出し、`ANALYZE` を実行するスクリプトの設計
- 通常のローカルテーブルおよびパーティションテーブルの統計情報更新

### 対象外とする項目

- 外部テーブル（Foreign Tables）やFDWを介したテーブルへの対応
- PostgreSQL 以外の RDBMS（MySQL, Oracle, SQL Server など）への対応  
  ※現時点では PostgreSQL のみを対象とするが、本プロジェクトの成果が安定・有効と判断されれば、他の主要RDBMSへの拡張も将来的な検討対象とする。
- 自動統計情報更新の PostgreSQL 本体の挙動変更や、サーバパラメータの制御
- Web UI やダッシュボードによる可視化機能（将来的な拡張対象）

### 想定環境

- PostgreSQL 13 以上を対象とし、特に `parallel analyze` の恩恵を受けられるバージョンを想定
- 開発・実行環境はローカルPCまたは軽量VPS
- 本番環境への導入は将来的なPoC結果に基づき判断


---


# 全体構成

本ツールは、PostgreSQLの統計情報更新に関わるパフォーマンスを改善することを目的とし、  
AIによる最適なサンプリング行数の推定と、それに基づく `ANALYZE` 処理を実行するアプリケーションである。

初期フェーズではローカル実行環境を想定し、将来的にはクラウド環境やWeb UIとの統合も視野に入れている。

本ツールの構成は以下のコンポーネントにより構成される：


### 1. サンプリング最適化エンジン（AIロジック部）

- 過去の実行ログや統計情報をもとに、各テーブルに対する適切なサンプリング行数を推定
- 現在は単純なルールベース or 回帰モデルを採用
- 将来的に強化学習やクラスタリングへの展開も視野に入れる


### 2. メトリクス取得モジュール

- `pg_stat_all_tables`、`pg_stat_user_indexes`、`pg_class` などのシステムカタログから統計・構造情報を収集
- `reltuples`、`n_dead_tup`、カーディナリティ、相関係数などを収集対象とする


### 3. サンプリング実行・統計更新モジュール

- 推定されたサンプリング行数をもとに `ANALYZE` を適切に実行
- パーティションテーブルや部分インデックスに応じた実行制御も行う
- `ANALYZE` 実行後の統計情報（例：`reltuples`、`n_distinct`、`most_common_vals` など）や処理時間を  
  独自の履歴管理テーブルに記録し、AI学習データや運用分析に活用する


### 4. ログ・エラーハンドリング機構

- 実行結果や異常検知のログ出力
- エラー発生時のリトライ処理、無効な対象へのスキップ処理などを実装予定


### 5. （将来的な構想）Web UI / API連携モジュール

- クエリパターンや予測モデルの可視化
- サンプリング精度や効果の分析画面
- バックエンドAPI連携によるCI/CD統合の検討


---


# 機能要件

本ツールが満たすべき機能要件は以下の通りである。

### 1. サンプリング行数の推定
- 各テーブルに対し、過去の実行ログや統計情報をもとに最適なサンプリング行数を推定する。
- 初期フェーズではルールベースまたは回帰モデルを用い、将来的には強化学習への対応も視野に入れる。

### 2. メトリクスの収集

本ツールでは、初期段階として以下の統計情報およびメタ情報を PostgreSQL から収集対象とする：

- 使用するシステムカタログ：
  - `pg_stat_all_tables`
  - `pg_stat_user_indexes`
  - `pg_class`
  - `pg_attribute`
  - `pg_stats`

- 収集する主な項目：
  - テーブル行数（`reltuples`）
  - 空き領域や断片化の程度（`n_dead_tup`）
  - カーディナリティ、相関係数、`n_distinct` などの列単位の情報

なお、今後の実装過程や性能検証を通じて、必要に応じて他のカタログビューや内部統計情報の収集も視野に入れている。たとえば `pg_stat_progress_analyze` や `pg_stat_io`、拡張統計情報（extended statistics）などが対象候補として挙げられる。


### 3. ANALYZEの実行制御
- 推定された行数に応じて `ANALYZE` を動的に実行する。
- パーティションテーブルや部分インデックスを考慮し、適切なスコープで `ANALYZE` を発行する。
- 対象外テーブル（foreign tablesなど）はスキップする。

### 4. ログ記録および異常検知
- 実行結果（推定値、実行時間、更新結果など）をログとして記録する。
- エラー発生時には適切にログ出力し、再実行やスキップ処理を実装する。

### 5. 設定ファイルおよびパラメータ制御
- ユーザーが対象スキーマや対象外テーブル、閾値などを設定ファイルで指定できるようにする。
- 実行モード（dry-run、実行モードなど）を切り替え可能にする。

### 6. スケジューラやCI/CDとの連携（将来的機能）
- cronやジョブスケジューラとの連携を想定したバッチ実行機能。
- CI/CDツールと連携した自動化の仕組みの構築。



---


# 非機能要件

本ツールの非機能要件は、主に実行効率・保守性・運用性・拡張性を考慮して定義される。  
また、基本設計段階で必要となる各種しきい値や制約条件についても初期値を設け、将来的な自動調整や運用最適化の基盤とする。

## 1. パフォーマンス

- 大規模なテーブルに対しても、数分以内で統計情報の収集と更新が完了することを目指す。
- サンプリングによる高速な統計収集を前提とし、必要に応じてフルスキャンとの比較も行う。
- 実行時のメモリ消費量やCPU使用率を監視し、過剰なリソース消費を回避する。

### 初期しきい値（パフォーマンス関連）

| 項目 | 説明 | 初期値（例） |
|------|------|-------------|
| 最大許容実行時間 | 1テーブルの処理時間上限 | 60秒 |
| メモリ使用上限 | プロセス単位のメモリ制限 | 1GB |
| 並列実行数 | 同時ANALYZE数 | 1～4スレッド |



## 2. 可用性・安定性

- エラー発生時にはログを記録しつつ、安全に処理を終了・スキップする機構を持つ。
- 予期しない異常終了を防ぐフェールセーフ機構を実装する。

### 初期しきい値（異常検知・リトライ）

| 項目 | 説明 | 初期値（例） |
|------|------|-------------|
| リトライ回数 | 一時的な失敗の再試行 | 最大3回 |
| 統計収集失敗時の対応 | 無効な統計が返った場合 | スキップ＋ログ出力 |



## 3. 保守性

- モジュール単位での変更が容易な構成とする。
- ログ出力やエラー内容を確認しやすく、トラブルシューティングが容易であること。



## 4. 拡張性

- PostgreSQL以外のRDBMSへの対応や、新たな統計項目の追加が可能な構成とする。
- 将来的なWeb UI連携や外部API連携に備えたモジュール分離を意識した設計とする。



## 5. 実行環境と互換性

- 初期リリースは PostgreSQL 15系 + Linux環境 でのローカル実行を前提とする。
- 将来的にクラウド環境（例：AWS RDS、GCP Cloud SQL）への対応も視野に入れる。



## 6. セキュリティ

- 不正なSQLやサーバパラメータを入力された際にも、影響範囲を最小限に抑える。
- 実行ユーザには最小限の権限（SELECT/ANALYZE）で動作可能な構成とする。




## 7. ロギング・監査

- 実行結果、処理対象、処理時間、推定サンプリング値などをログとして記録。
- 後続分析やパフォーマンス評価のためのCSV出力なども検討する。

### 初期しきい値（ログ関連）

| 項目 | 説明 | 初期値（例） |
|------|------|--------------|
| 実行ログ出力条件 | クエリ実行時間に応じてログ出力 | 5秒超過時のみ出力（※1） |

※1：初期状態では5秒をスロークエリのしきい値とし、それを超えるクエリのみログ出力。将来的には動的調整や平均応答時間に応じたしきい値制御の拡張も想定。


## 8. テーブル選定条件・サンプリング設定

- テーブルの行数やスキーマ、種別によって処理対象を選定する。
- サンプリング率や対象除外条件は、初期値を設けるが将来的にAIで動的に調整予定。

### 初期しきい値（選定・サンプリング関連）

| 項目 | 説明 | 初期値（例） |
|------|------|-------------|
| 最小行数閾値 | 対象とする最低行数 | 設定せず（※1） |
| 除外スキーマ名 | 処理対象から除外 | pg_catalog, information_schema |
| 外部テーブル除外 | 外部テーブルと判定される属性（※2） | 除外対象 |
| サンプリング行数 | ANALYZEで使用されるサンプル数 | PostgreSQLの統計設定（※3）に基づき自動調整 |
| default_statistics_target | 列単位統計の粒度 | 100（PostgreSQL初期値） |
| 統計更新頻度制限 | 再実行を避ける調整 | 1時間 or 1日単位で間引き可（手動設定可）※4 |

※1：データ量が大幅に減少（例：1万件→5千件など）した場合にも統計情報の更新対象としたいため、初期段階ではあえて固定の最小行数閾値は設けない。将来的にはデータ変動量やAIによる動的判定ロジックの導入を想定しており、そのため柔軟性を重視した設計としている。

※2：PostgreSQLでは、`pg_class.relkind` が `'f'` の場合、そのテーブルは「外部テーブル（foreign table）」として定義されている。fdw（foreign data wrapper）経由で外部ソースに接続しているテーブルのため、統計情報の更新対象から除外するのが一般的。

※3：PostgreSQLでは、`default_statistics_target` の設定値や列数、統計の種類などをもとに、ANALYZE時に必要なサンプリング行数が内部的に決定されます。本ツールではこの仕組みを前提としつつ、必要に応じて調整を検討します。

※4：将来的には、pg_stat_xxx やクエリ実行時間などを常時監視し、パフォーマンス劣化の兆候をもとに、統計情報の更新タイミングをAI的に自動制御する仕組みへの拡張を想定。


## 備考と補足

- 各しきい値は「初期値」であり、**運用やAIによる動的最適化**を前提とする。
- バージョン・実行環境（オンプレ／クラウド）により変動しやすいため、**環境変数や設定ファイルで上書き可能**にしておくことが望ましい。

